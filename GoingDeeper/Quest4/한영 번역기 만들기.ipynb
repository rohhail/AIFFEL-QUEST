{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c012ccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab34dc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "%config InlineBackend.figure_format = 'retina'\n",
    " \n",
    "import matplotlib.font_manager as fm\n",
    "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "font = fm.FontProperties(fname=fontpath, size=9)\n",
    "plt.rc('font', family='NanumBarunGothic') \n",
    "mpl.font_manager.findfont(font)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572bd947",
   "metadata": {},
   "source": [
    "# 1. 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3917b226",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_kor_file = \"data/korean-english-park.train.ko\"\n",
    "path_eng_file = \"data/korean-english-park.train.en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fdec026",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 94123\n",
      "Example:\n",
      ">> 개인용 컴퓨터 사용의 상당 부분은 \"이것보다 뛰어날 수 있느냐?\"\n",
      ">> 북한의 핵무기 계획을 포기하도록 하려는 압력이 거세지고 있는 가운데, 일본과 북한의 외교관들이 외교 관계를 정상화하려는 회담을 재개했다.\n",
      ">> \"경호 로보트가 침입자나 화재를 탐지하기 위해서 개인적으로, 그리고 전문적으로 사용되고 있습니다.\"\n",
      ">> 수자원부 당국은 논란이 되고 있고, 막대한 비용이 드는 이 사업에 대해 내년에 건설을 시작할 계획이다.\n",
      ">> 또한 근력 운동은 활발하게 걷는 것이나 최소한 20분 동안 뛰는 것과 같은 유산소 활동에서 얻는 운동 효과를 심장과 폐에 주지 않기 때문에, 연구학자들은 근력 운동이 심장에 큰 영향을 미치는지 여부에 대해 논쟁을 해왔다.\n"
     ]
    }
   ],
   "source": [
    "with open(path_kor_file, \"r\") as f:\n",
    "    kor_raw = f.read().splitlines()\n",
    "    \n",
    "print(\"Data Size:\", len(kor_raw))\n",
    "print(\"Example:\")\n",
    "\n",
    "for sen in kor_raw[0:100][::20]: print(\">>\", sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb25523a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 94123\n",
      "Example:\n",
      ">> Much of personal computing is about \"can you top this?\"\n",
      ">> Amid mounting pressure on North Korea to abandon its nuclear weapons program Japanese and North Korean diplomats have resumed talks on normalizing diplomatic relations.\n",
      ">> “Guard robots are used privately and professionally to detect intruders or fire,” Karlsson said.\n",
      ">> Authorities from the Water Resources Ministry plan to begin construction next year on the controversial and hugely expensive project.\n",
      ">> Researchers also have debated whether weight-training has a big impact on the heart, since it does not give the heart and lungs the kind of workout they get from aerobic activities such as brisk walking or running for at least 20 minutes.\n"
     ]
    }
   ],
   "source": [
    "with open(path_eng_file, \"r\") as f:\n",
    "    eng_raw = f.read().splitlines()\n",
    "    \n",
    "print(\"Data Size:\", len(eng_raw))\n",
    "print(\"Example:\")\n",
    "\n",
    "for sen in eng_raw[0:100][::20]: print(\">>\", sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f4fdc9",
   "metadata": {},
   "source": [
    "# 2. 데이터 전처리 & 토큰화\n",
    "\n",
    "Step 2. 데이터 정제\n",
    "\n",
    "1. set 데이터형이 중복을 허용하지 않는다는 것을 활용해 중복된 데이터를 제거하도록 합니다. 데이터의 병렬 쌍이 흐트러지지 않게 주의하세요! 중복을 제거한 데이터를 cleaned_corpus 에 저장합니다.\n",
    "2. 앞서 정의한 preprocessing() 함수는 한글에서는 동작하지 않습니다. 한글에 적용할 수 있는 정규식을 추가하여 함수를 재정의하세요!\n",
    "3. 타겟 언어인 영문엔 \\<start\\> 토큰과 \\<end\\> 토큰을 추가하고 split() 함수를 이용하여 토큰화합니다. 한글 토큰화는 KoNLPy의 mecab 클래스를 사용합니다.\n",
    "\n",
    "모든 데이터를 사용할 경우 학습에 굉장히 오랜 시간이 걸립니다. cleaned_corpus로부터 토큰의 길이가 40 이하인 데이터를 선별하여 eng_corpus와 kor_corpus를 각각 구축하세요.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07e5c36",
   "metadata": {},
   "source": [
    "## 2-1) 중복 데이터 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "533671a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#중복 제거\n",
    "unique_pairs = set(zip(kor_raw, eng_raw))#쌍튜플을 set자료형 변환\n",
    "\n",
    "#리스트 변환\n",
    "kor_lines, eng_lines = zip(*unique_pairs) #튜플 unpacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6a02750",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('이제 많은 은행들은 기본적인 계좌 정보 이상의 것을 제공하는 직원을 24시간 충원시키고 있다.', '그는 이라키야 TV에서 “경찰이 알 마스리가 은신한 민가를 불시에 급습해 그를 체포했다”며 “초동 수사에서 그가 이라크 내 알카에다 지도자 아부 함자 알 무하지르라고 자백했다”고 말했다.', '북한은 지난해 핵실험을 강행해 미국과의 긴장관계가 조성됐으나 그 이후 핵시설의 불능화를 약속해 6자회담이 다시 성사됐다.', 'AP 라디오 뉴스입니다.', '10일간 계속되고 있는 이스라엘의 군사 행동으로 팔레스타인인 500여명이 사망하고 있음에도 불구하고 이날 하마스 무장단체는 이스라엘 남부로 수십 차례 로켓 공격을 감행했다.')\n",
      "('Now many banks are adding warm bodies around the clock who provide much more than basic account information.', '\"The police raided this house and arrested him. During the primary investigation, he confessed that he is Abu Hamza Al-Muhajir, the leader of al Qaeda in Iraq.', 'The meeting comes at a time of talks over disarmament, with North Korean negotiators set to respond Tuesday to the latest road map. Last year, the North tested a nuclear bomb, rattling regional stability and leading to a dramatic turnaround in a previously hard-line U.S. policy.', 'Our Ed Donahue takes a look at his long career:', 'On Monday Hamas militants fired dozens of rockets into southern Israel despite a 10-day Israeli military campaign that reportedly has left more than 500 Palestinians dead.')\n"
     ]
    }
   ],
   "source": [
    "print(kor_lines[:5])\n",
    "print(eng_lines[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "460c0dfd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78968 78968\n"
     ]
    }
   ],
   "source": [
    "print(len(kor_lines), len(eng_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca53d9e8",
   "metadata": {},
   "source": [
    "## 2-2) 길이가 40 이하인 데이터 선별 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "156fda68",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 40 #최대길이\n",
    "\n",
    "filtered_kor_lines, filtered_eng_lines = [], []\n",
    "\n",
    "for koc, enc in zip(kor_lines, eng_lines):\n",
    "    if len(koc.split()) <= max_len and len(enc.split()) <= max_len:\n",
    "        filtered_kor_lines.append(koc)\n",
    "        filtered_eng_lines.append(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12bd6845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75577 75577\n"
     ]
    }
   ],
   "source": [
    "print(len(filtered_kor_lines), len(filtered_eng_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3391956e",
   "metadata": {},
   "source": [
    "## 2-3)한글에 적용할 수 있는 정규식을 추가하여 함수를 재정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d251a372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence, s_token=False, e_token=False, korean = True):\n",
    "    sentence = sentence.lower().strip() #소문자 변환\n",
    "    \n",
    "    regex = re.compile(r\"([?.!,])\")\n",
    "    sentence = regex.sub(r\" \\1 \", sentence)\n",
    "    #\\1 : 일치하는 특수 문자(?, !, .)를 나타냄\n",
    "    # r\" \\1 \"는 일치하는 특수 문자 앞뒤에 공백을 추가\n",
    "    \n",
    "    regex = re.compile(r'[\" \"]+')\n",
    "    sentence = regex.sub(\" \", sentence) #불필요한 공백 제거\n",
    "    \n",
    "    #한국어와 영어의 데이터 전처리\n",
    "    if korean:\n",
    "        regex = re.compile(r\"[^가-힣?.!,]+\")\n",
    "        sentence = regex.sub(\" \", sentence)#불필요한 문자 제거\n",
    "    else :\n",
    "        sentence = sentence.lower().strip() #소문자 변환\n",
    "        regex = re.compile(r\"[^a-zA-Z?.!,]+\")\n",
    "        sentence = regex.sub(\" \", sentence)#불필요한 문자 제거\n",
    "\n",
    "    sentence = sentence.strip()#공백제거\n",
    "\n",
    "    if s_token:\n",
    "        sentence = '<start> ' + sentence\n",
    "\n",
    "    if e_token:\n",
    "        sentence += ' <end>'\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b37df79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Korean: 라디오 뉴스입니다 .\n",
      "English: <start> our ed donahue takes a look at his long career <end>\n"
     ]
    }
   ],
   "source": [
    "enc_corpus = []\n",
    "dec_corpus = []\n",
    "\n",
    "num_examples = 20000\n",
    "\n",
    "for kor,eng in zip(filtered_kor_lines[:num_examples], \n",
    "                   filtered_eng_lines[:num_examples]):\n",
    "    enc_corpus.append(preprocess_sentence(kor))\n",
    "    dec_corpus.append(preprocess_sentence(eng, \n",
    "                                          s_token=True, \n",
    "                                          e_token=True,\n",
    "                                          korean = False))\n",
    "\n",
    "\n",
    "print(\"Korean:\", enc_corpus[2])\n",
    "print(\"English:\", dec_corpus[2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e90d1c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Korean: 거의 년간의 은퇴 이후 이 세의 게임 쇼 진행자는 자신이 오랫동안 진행했던 퀴즈 프로그램에 나오라고 초청 받았습니다 .\n",
      "English: <start> i just wanted the truth to be told . <end>\n"
     ]
    }
   ],
   "source": [
    "print(\"Korean:\", enc_corpus[11])\n",
    "print(\"English:\", dec_corpus[11]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d04823",
   "metadata": {},
   "source": [
    "## 2-4) 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b679f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "def enc_tokenize(corpus):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=15000,\n",
    "                                                      filters='')\n",
    "    mecab = Mecab()\n",
    "    tokenized_corpus = []\n",
    "    \n",
    "    for sen in corpus:\n",
    "        tokenized_sen = mecab.morphs(sen) #토큰화\n",
    "        tokenized_corpus.append(tokenized_sen)\n",
    "        \n",
    "    tokenizer.fit_on_texts(tokenized_corpus)\n",
    "    \n",
    "    sequences = tokenizer.texts_to_sequences(tokenized_corpus)  # 정수 인코딩\n",
    "    padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, \n",
    "                                                                     padding='post')  # 패딩\n",
    "\n",
    "    return padded_sequences, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72de2bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#영어 토큰화 함수\n",
    "def dec_tokenize(corpus):\n",
    "    #토크나이저 객체생성, filters = ' ' :특수문자 필터링 비활성황 \n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=15000,\n",
    "                                                      filters='')\n",
    "    \n",
    "    #텍스트 말뭉치(corpus)에 등장하는 모든 단어를 분석하고 각 단어에 고유한 정수 인덱스를 부여\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "    #텍스트 말뭉치를 정수 시퀀스로 변환\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, \n",
    "                                                           padding='post')\n",
    "\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e290e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train, enc_tokenizer = enc_tokenize(enc_corpus)\n",
    "dec_train, dec_tokenizer = dec_tokenize(dec_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e16056b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24768\n"
     ]
    }
   ],
   "source": [
    "print(len(enc_tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d75420a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25573\n"
     ]
    }
   ],
   "source": [
    "print(len(dec_tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f5dc315",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 77)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d78170fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 53)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366cfa6d",
   "metadata": {},
   "source": [
    "# 3. 모델설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d67463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.w_dec = tf.keras.layers.Dense(units)\n",
    "        self.w_enc = tf.keras.layers.Dense(units)\n",
    "        self.w_com = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, h_enc, h_dec):\n",
    "        # h_enc shape: [batch x length x units]\n",
    "        # h_dec shape: [batch x units]\n",
    "\n",
    "        h_enc = self.w_enc(h_enc)\n",
    "        h_dec = tf.expand_dims(h_dec, 1)\n",
    "        h_dec = self.w_dec(h_dec)\n",
    "\n",
    "        score = self.w_com(tf.nn.tanh(h_dec + h_enc))\n",
    "        \n",
    "        attn = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        context_vec = attn * h_enc\n",
    "        context_vec = tf.reduce_sum(context_vec, axis=1)\n",
    "\n",
    "        return context_vec, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77ad8c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(enc_units,\n",
    "                                       return_sequences=True)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.gru(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d28253e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, h_dec, enc_out):\n",
    "        context_vec, attn = self.attention(enc_out, h_dec)\n",
    "\n",
    "        out = self.embedding(x)\n",
    "        out = tf.concat([tf.expand_dims(context_vec, 1), out], axis=-1)\n",
    "        \n",
    "        out, h_dec = self.gru(out)\n",
    "        out = tf.reshape(out, (-1, out.shape[2]))\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out, h_dec, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1eb1c72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Output: (64, 54, 1024)\n",
      "Decoder Output: (64, 25574)\n",
      "Decoder Hidden State: (64, 1024)\n",
      "Attention: (64, 54, 1)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE     = 64\n",
    "SRC_VOCAB_SIZE = len(enc_tokenizer.index_word) + 1\n",
    "TGT_VOCAB_SIZE = len(dec_tokenizer.index_word) + 1\n",
    "\n",
    "units         = 1024\n",
    "embedding_dim = 512\n",
    "\n",
    "encoder = Encoder(SRC_VOCAB_SIZE, embedding_dim, units)\n",
    "decoder = Decoder(TGT_VOCAB_SIZE, embedding_dim, units)\n",
    "\n",
    "# sample input\n",
    "sequence_len = 54\n",
    "\n",
    "sample_enc = tf.random.uniform((BATCH_SIZE, sequence_len))\n",
    "sample_output = encoder(sample_enc)\n",
    "\n",
    "print ('Encoder Output:', sample_output.shape)\n",
    "\n",
    "sample_state = tf.random.uniform((BATCH_SIZE, units))\n",
    "\n",
    "sample_logits, h_dec, attn = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                     sample_state, sample_output)\n",
    "\n",
    "print ('Decoder Output:', sample_logits.shape)\n",
    "print ('Decoder Hidden State:', h_dec.shape)\n",
    "print ('Attention:', attn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e295b914",
   "metadata": {},
   "source": [
    "# 4. 훈련하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c853fa",
   "metadata": {},
   "source": [
    "## 4-1) train, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "342c1dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ed6132",
   "metadata": {},
   "source": [
    "## 4-2) train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbb9d936",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(src, tgt, encoder, decoder, optimizer, dec_tok):\n",
    "    bsz = src.shape[0]\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_out = encoder(src)\n",
    "        h_dec = enc_out[:, -1]\n",
    "        \n",
    "        dec_src = tf.expand_dims([dec_tok.word_index['<start>']] * bsz, 1)\n",
    "\n",
    "        for t in range(1, tgt.shape[1]):\n",
    "            pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
    "\n",
    "            loss += loss_function(tgt[:, t], pred)\n",
    "            dec_src = tf.expand_dims(tgt[:, t], 1)\n",
    "        \n",
    "    batch_loss = (loss / int(tgt.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ad7cce",
   "metadata": {},
   "source": [
    "## 4-3) training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d194d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1: 100%|██████████| 313/313 [06:13<00:00,  1.19s/it, Loss 3.2653]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm    # tqdm\n",
    "import random\n",
    "\n",
    "EPOCHS = 1\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)    # tqdm\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss = train_step(enc_train[idx:idx+BATCH_SIZE],\n",
    "                                dec_train[idx:idx+BATCH_SIZE],\n",
    "                                encoder,\n",
    "                                decoder,\n",
    "                                optimizer,\n",
    "                                dec_tokenizer)\n",
    "    \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))    # tqdm\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))    # tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940be983",
   "metadata": {},
   "source": [
    "# 5. 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d87b315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다 .\n",
      "Predicted translation: the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_120/1483439765.py:45: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
      "/tmp/ipykernel_120/1483439765.py:46: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 631,
       "width": 75
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate(sentence, encoder, decoder):\n",
    "    attention = np.zeros((dec_train.shape[-1], enc_train.shape[-1]))\n",
    "    \n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    inputs = enc_tokenizer.texts_to_sequences([sentence.split()])\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
    "                                                           maxlen=enc_train.shape[-1],\n",
    "                                                           padding='post')\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    enc_out = encoder(inputs)\n",
    "\n",
    "    dec_hidden = enc_out[:, -1]\n",
    "    dec_input = tf.expand_dims([dec_tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(dec_train.shape[-1]):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0]).numpy()\n",
    "\n",
    "        result += dec_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if dec_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention\n",
    "\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention\n",
    "\n",
    "\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def translate(sentence, encoder, decoder):\n",
    "    result, sentence, attention = evaluate(sentence, encoder, decoder)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    \n",
    "    attention = attention[:len(result.split()), :len(sentence.split())]\n",
    "    plot_attention(attention, sentence.split(), result.split(' '))\n",
    "\n",
    "\n",
    "translate(\"오바마는 대통령이다.\", encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08166efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"오바마는 대통령이다.\",\n",
    "             \"시민들은 도시 속에 산다.\", \n",
    "             \"커피는 필요 없다.\",\n",
    "             \"일곱 명의 사망자가 발생했다.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a0498a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다 .\n",
      "Predicted translation: the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the \n",
      "Input: 시민들은 도시 속에 산다 .\n",
      "Predicted translation: the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the , the \n",
      "Input: 커피는 필요 없다 .\n",
      "Predicted translation: the , the the , the the , the the , the the , the the , the the , the the , the the , the the , the the , the the , the the , the the , the the , the the , the the , the the , \n",
      "Input: 일곱 명의 사망자가 발생했다 .\n",
      "Predicted translation: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the \n"
     ]
    }
   ],
   "source": [
    "def translate(sentence, encoder, decoder):\n",
    "    result, sentence, attention = evaluate(sentence, encoder, decoder)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    \n",
    "for sen in sentences:\n",
    "    translate(sen, encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee3fb5b",
   "metadata": {},
   "source": [
    "# 6. 결과 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c780b3",
   "metadata": {},
   "source": [
    "## 6-1) 첫번째 시도 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff00fa0",
   "metadata": {},
   "source": [
    "Input: 오바마는 대통령이다 .\n",
    "\n",
    "Predicted translation: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0746b305",
   "metadata": {},
   "source": [
    "- LMS 코드와 동일한 프로세스로 진행을 하였지만, 코드가 위와같이 작동하지 않았음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d21d1c",
   "metadata": {},
   "source": [
    "학습 데이터량 10000 > 20000 증강 후 재 테스트 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1afd281",
   "metadata": {},
   "source": [
    "## 6-2) 두번째 시도 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b270187",
   "metadata": {},
   "source": [
    "- Input: 오바마는 대통령이다 .\n",
    "\n",
    "Predicted translation: books processors exploration betina cor sprung hopeless magnetic rig dmitry behaved cano telescopes gawker mesopotamia canberra strafe hauled fidel angie maintenance enters simba bands skibo shotaro probation gravest differently deteriorates morici bulb utterly divine pedro coal separatist toledo lucinda mike bergen swiveling superstar trimmed rodriguez applied global dissatisfaction constable looped varshavyanka \n",
    "- Input: 시민들은 도시 속에 산다 .\n",
    "\n",
    "Predicted translation: books processors exploration betina cor sprung hopeless magnetic rig dmitry behaved cano telescopes gawker mesopotamia canberra strafe hauled fidel angie maintenance enters simba bands skibo shotaro probation gravest differently deteriorates morici bulb utterly divine pedro coal separatist toledo lucinda mike bergen swiveling superstar trimmed rodriguez applied global dissatisfaction constable looped varshavyanka \n",
    "- Input: 커피는 필요 없다 .\n",
    "\n",
    "Predicted translation: books processors exploration betina cor sprung hopeless magnetic rig dmitry behaved cano telescopes gawker mesopotamia canberra strafe hauled fidel angie maintenance enters simba bands skibo shotaro probation gravest differently deteriorates morici bulb utterly divine pedro coal separatist toledo lucinda mike bergen swiveling superstar trimmed rodriguez applied global dissatisfaction constable looped varshavyanka \n",
    "- Input: 일곱 명의 사망자가 발생했다 .\n",
    "\n",
    "Predicted translation: books processors exploration betina cor sprung hopeless magnetic rig dmitry behaved cano telescopes gawker mesopotamia canberra strafe hauled fidel angie maintenance enters simba bands skibo shotaro probation gravest differently deteriorates morici bulb utterly divine pedro coal separatist toledo lucinda mike bergen swiveling superstar trimmed rodriguez applied global dissatisfaction constable looped varshavyanka "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39cbeb3",
   "metadata": {},
   "source": [
    "- 구조적인 문제가 있는 것으로 예상됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c46be0",
   "metadata": {},
   "source": [
    "# 6-3) 세번째 시도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b29e65",
   "metadata": {},
   "source": [
    "- 학습 데이터량을 20000으로 고정하고, 단어사전의 개수를 10000 -> 15000으로 진행\n",
    "- epoch 수 5-> 10 변경후 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204a5251",
   "metadata": {},
   "source": [
    "- Input: 오바마는 대통령이다 .\n",
    "- Predicted translation: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the \n",
    "- Input: 시민들은 도시 속에 산다 .\n",
    "- Predicted translation: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the \n",
    "- Input: 커피는 필요 없다 .\n",
    "- Predicted translation: the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the \n",
    "- Input: 일곱 명의 사망자가 발생했다 .\n",
    "- Predicted translation: the government , the government , the government , the government , the government , the government , the government , the government , the government , the government , the government , the government , the government , the government , the government , the government , the government , the government , the government , the "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488af40a",
   "metadata": {},
   "source": [
    "### 후기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c19c00a",
   "metadata": {},
   "source": [
    "1. 배운점\n",
    "- attention 모델의 종류와 모델 구성에 대해서 알게 되었다\n",
    "- SeqtoSeq 모델의 학습속도가 너무 느리다는 것을 알게되었다.\n",
    "\n",
    "2. 아쉬운점\n",
    "- 학습속도가 너무 느려서 다양한 하이퍼파라미터에 대한 학습과정을 test해보지 못한것\n",
    "\n",
    "3. 느낀점\n",
    "- 수학적으로는 이해하기 어려웠는데 코드로 접근하니까 이해할 수 있었던 부분이 많았다.\n",
    "\n",
    "4. 어려웠던점\n",
    "- 모델구현이 생각보다 너무 안되서 해결해보고 싶었지만 학습 시간과 GPU의 한계로 그러지 못하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d77748",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
