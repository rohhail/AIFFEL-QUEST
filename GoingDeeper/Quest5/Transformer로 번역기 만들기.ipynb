{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a33e091c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "1.21.4\n",
      "3.4.3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import numpy\n",
    "import matplotlib\n",
    "\n",
    "print(tensorflow.__version__)\n",
    "print(numpy.__version__)\n",
    "print(matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "09f0b385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "%config InlineBackend.figure_format = 'retina'\n",
    " \n",
    "import matplotlib.font_manager as fm\n",
    "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "font = fm.FontProperties(fname=fontpath, size=9)\n",
    "plt.rc('font', family='NanumBarunGothic') \n",
    "mpl.font_manager.findfont(font)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d52be54",
   "metadata": {},
   "source": [
    "# 1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c214734",
   "metadata": {},
   "source": [
    "## 1-1) 데이터 정제 및 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3fd6f030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = os.getenv('HOME')+'/aiffel/transformer/data'\n",
    "kor_path = data_dir+\"/korean-english-park.train.ko\"\n",
    "eng_path = data_dir+\"/korean-english-park.train.en\"\n",
    "\n",
    "# 데이터 정제 및 토큰화\n",
    "def clean_corpus(kor_path, eng_path):\n",
    "    \n",
    "    with open(kor_path, \"r\") as f: kor = f.read().splitlines()\n",
    "    with open(eng_path, \"r\") as f: eng = f.read().splitlines()\n",
    "    assert len(kor) == len(eng)\n",
    "\n",
    "    #중복제거\n",
    "    cleaned_corpus = set(zip(kor,eng))\n",
    "    \n",
    "    cleaned_kor, cleaned_eng = zip(*cleaned_corpus)\n",
    "    cleaned_corpus = list(zip(cleaned_kor, cleaned_eng))\n",
    "    \n",
    "    cleaned_corpus = [\"\\t\".join(pair) for pair in cleaned_corpus]\n",
    "    \n",
    "    return cleaned_corpus\n",
    "\n",
    "cleaned_corpus = clean_corpus(kor_path, eng_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5dc0bca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78968\n"
     ]
    }
   ],
   "source": [
    "print(len(cleaned_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc71335",
   "metadata": {},
   "source": [
    "## 1-2) 정제함수 정의\n",
    "\n",
    "- 모든 입력을 소문자로 변환합니다.\n",
    "- 알파벳, 문장부호, 한글만 남기고 모두 제거합니다.\n",
    "- 문장부호 양옆에 공백을 추가합니다.\n",
    "- 문장 앞뒤의 불필요한 공백을 제거합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b2938509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip() #소문자 변환\n",
    "\n",
    "    #문장부호 양옆에 공백을 추가\n",
    "    regex = re.compile(r\"([?.!,])\")\n",
    "    sentence = regex.sub(r\" \\1 \", sentence)\n",
    "    #\\1 : 일치하는 특수 문자(?, !, .)를 나타냄\n",
    "    # r\" \\1 \"는 일치하는 특수 문자 앞뒤에 공백을 추가\n",
    "\n",
    "    regex = re.compile(r'[\" \"]+')\n",
    "    sentence = regex.sub(\" \", sentence) #불필요한 공백 제거\n",
    "\n",
    "    regex = re.compile(r\"[^a-zA-Z가-힣?.!,]+\")\n",
    "    sentence = regex.sub(\" \", sentence)#불필요한 문자 제거\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f92cda9",
   "metadata": {},
   "source": [
    "## 1-3) 토큰화\n",
    "\n",
    "한글 말뭉치 kor_corpus 와 영문 말뭉치 eng_corpus 를 각각 분리한 후, 정제하여 토큰화를 진행합니다! 토큰화에는 Sentencepiece를 활용하세요.\n",
    " 첨부된 공식 사이트를 참고해 아래 조건을 만족하는 generate_tokenizer() 함수를 정의합니다.\n",
    " 최종적으로 ko_tokenizer 과 en_tokenizer 를 얻으세요. en_tokenizer에는 set_encode_extra_options(\"bos:eos\") 함수를 실행해 타겟 입력이 문장의 시작 토큰과 끝 토큰을 포함할 수 있게 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "712e13bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=ko.txt --model_prefix=ko --vocab_size=20000 --pad_id=0 --bos_id=1 --eos_id=2 --unk_id=3\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ko.txt\n",
      "  input_format: \n",
      "  model_prefix: ko\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 20000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 3\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: ko.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 78968 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=5053323\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9501% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=1185\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999501\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 78967 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 159138 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 78967\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 195706\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 195706 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=83228 obj=12.5937 num_tokens=378608 num_tokens/piece=4.54905\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=70410 obj=11.4417 num_tokens=379922 num_tokens/piece=5.39585\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=52802 obj=11.4471 num_tokens=396861 num_tokens/piece=7.51602\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=52784 obj=11.4136 num_tokens=397192 num_tokens/piece=7.52486\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=39588 obj=11.5538 num_tokens=420665 num_tokens/piece=10.6261\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=39588 obj=11.5172 num_tokens=420679 num_tokens/piece=10.6264\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=29691 obj=11.7107 num_tokens=446988 num_tokens/piece=15.0547\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=29691 obj=11.6693 num_tokens=446992 num_tokens/piece=15.0548\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=22268 obj=11.9067 num_tokens=473392 num_tokens/piece=21.2588\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=22268 obj=11.8609 num_tokens=473387 num_tokens/piece=21.2586\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=22000 obj=11.8792 num_tokens=474446 num_tokens/piece=21.5657\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=22000 obj=11.8767 num_tokens=474444 num_tokens/piece=21.5656\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: ko.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: ko.vocab\n",
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=en.txt --model_prefix=en --vocab_size=20000 --pad_id=0 --bos_id=1 --eos_id=2 --unk_id=3\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: en.txt\n",
      "  input_format: \n",
      "  model_prefix: en\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 20000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 3\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: en.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 78968 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=10661485\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9909% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=29\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999909\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 78956 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 82992 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 78956\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 44562\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 44562 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=34535 obj=9.86221 num_tokens=83351 num_tokens/piece=2.41352\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=25851 obj=8.00619 num_tokens=83809 num_tokens/piece=3.242\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=21977 obj=7.92346 num_tokens=84668 num_tokens/piece=3.85257\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=21848 obj=7.90465 num_tokens=84910 num_tokens/piece=3.8864\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: en.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: en.vocab\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "# Sentencepiece를 활용하여 학습한 tokenizer를 생성합니다.\n",
    "def generate_tokenizer(corpus,\n",
    "                        vocab_size,\n",
    "                        lang=\"ko\",\n",
    "                        pad_id=0,\n",
    "                        bos_id=1,\n",
    "                        eos_id=2,\n",
    "                        unk_id=3):\n",
    "    \n",
    "    with open(f\"{lang}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for sentence in corpus:\n",
    "            f.write(sentence + \"\\n\")  # 각 문장을 줄바꿈으로 구분하여 저장\n",
    "        \n",
    "    # SentencePiece 모델 학습\n",
    "    spm.SentencePieceTrainer.train(\n",
    "        f\"--input={lang}.txt --model_prefix={lang} --vocab_size={vocab_size} --pad_id={pad_id} --bos_id={bos_id} --eos_id={eos_id} --unk_id={unk_id}\"\n",
    "    )\n",
    "\n",
    "    # SentencePieceProcessor 생성 및 반환\n",
    "    tokenizer = spm.SentencePieceProcessor()\n",
    "    tokenizer.load(f\"{lang}.model\")\n",
    "\n",
    "    return tokenizer\n",
    "    \n",
    "\n",
    "SRC_VOCAB_SIZE = TGT_VOCAB_SIZE = 20000\n",
    "\n",
    "eng_corpus = []\n",
    "kor_corpus = []\n",
    "\n",
    "for pair in cleaned_corpus:\n",
    "    k, e = pair.split(\"\\t\")\n",
    "\n",
    "    kor_corpus.append(preprocess_sentence(k))\n",
    "    eng_corpus.append(preprocess_sentence(e))\n",
    "\n",
    "ko_tokenizer = generate_tokenizer(kor_corpus, SRC_VOCAB_SIZE, \"ko\")\n",
    "en_tokenizer = generate_tokenizer(eng_corpus, TGT_VOCAB_SIZE, \"en\")\n",
    "en_tokenizer.set_encode_extra_options(\"bos:eos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c60146de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11500</th>\n",
       "      <td>▁주장했었다</td>\n",
       "      <td>-11.5971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>▁대해서</td>\n",
       "      <td>-8.7072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10404</th>\n",
       "      <td>투쟁</td>\n",
       "      <td>-11.4714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6523</th>\n",
       "      <td>ff</td>\n",
       "      <td>-10.8851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11960</th>\n",
       "      <td>▁불량</td>\n",
       "      <td>-11.6528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3168</th>\n",
       "      <td>▁동물원</td>\n",
       "      <td>-10.0703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8118</th>\n",
       "      <td>▁블룸버그</td>\n",
       "      <td>-11.1601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13777</th>\n",
       "      <td>▁prevent</td>\n",
       "      <td>-11.9072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7802</th>\n",
       "      <td>son</td>\n",
       "      <td>-11.0968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3956</th>\n",
       "      <td>▁비판했다</td>\n",
       "      <td>-10.3212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0        1\n",
       "11500    ▁주장했었다 -11.5971\n",
       "743        ▁대해서  -8.7072\n",
       "10404        투쟁 -11.4714\n",
       "6523         ff -10.8851\n",
       "11960       ▁불량 -11.6528\n",
       "3168       ▁동물원 -10.0703\n",
       "8118      ▁블룸버그 -11.1601\n",
       "13777  ▁prevent -11.9072\n",
       "7802        son -11.0968\n",
       "3956      ▁비판했다 -10.3212"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "vocab_list = pd.read_csv('ko.vocab', sep='\\t', header=None, quoting=csv.QUOTE_NONE)\n",
    "vocab_list.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "113fda74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c5a2b01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78968"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kor_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bb8449b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁안', '녕', '하', '세요', ',', '▁저', '는', '▁', 'AI', '▁개발', '자', '입니다', '.']\n",
      "['<s>', '▁', 'H', 'ello', ',', '▁', 'I', '▁am', '▁an', '▁', 'AI', '▁developer', '.', '</s>']\n"
     ]
    }
   ],
   "source": [
    "kor_sentence = \"안녕하세요, 저는 AI 개발자입니다.\"\n",
    "eng_sentence = \"Hello, I am an AI developer.\"\n",
    "\n",
    "kor_tokens = ko_tokenizer.encode_as_pieces(kor_sentence)\n",
    "eng_tokens = en_tokenizer.encode_as_pieces(eng_sentence)\n",
    "\n",
    "print(kor_tokens)  # [' 안녕', '하세요', ',', ' 저는', ' AI', ' 개발자', '입니다', '.']\n",
    "print(eng_tokens)  # [' ', 'Hello', ',', ' I', ' am', ' an', ' AI', ' developer', '.']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e93446",
   "metadata": {},
   "source": [
    "## 1-4) 패팅 처리 및 텐서 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f08772d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e630ef83b6b49efaa8f0c95f4b006cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm    # Process 과정을 보기 위해\n",
    "import tensorflow as tf\n",
    "\n",
    "src_corpus = []\n",
    "tgt_corpus = []\n",
    "\n",
    "assert len(kor_corpus) == len(eng_corpus)\n",
    "\n",
    "\n",
    "max_len = 50\n",
    "sen_len = 50000\n",
    "#20000 -> 50000 증강\n",
    "\n",
    "#문장 길이 저장 \n",
    "sentence_lengths_ko = []\n",
    "sentence_lengths_en = []\n",
    "\n",
    "for idx in tqdm(range(len(kor_corpus[:sen_len]))):\n",
    "    #토큰화\n",
    "    kor_tokens = ko_tokenizer.encode_as_pieces(kor_corpus[idx])\n",
    "    eng_tokens = en_tokenizer.encode_as_pieces(eng_corpus[idx])\n",
    "    \n",
    "    #문장길이 저장\n",
    "    sentence_lengths_ko.append(len(kor_tokens))\n",
    "    sentence_lengths_en.append(len(eng_tokens))\n",
    "    \n",
    "    # 토큰의 길이가 50 이하인 문장만 남깁니다. \n",
    "    if len(kor_tokens) <= 50 and len(eng_tokens) <= 50:\n",
    "        #숫자 인코딩 후 문자열에 추가\n",
    "        src_corpus.append(ko_tokenizer.encode_as_ids(kor_corpus[idx]))\n",
    "        tgt_corpus.append(en_tokenizer.encode_as_ids(eng_corpus[idx]))\n",
    "        \n",
    "        \n",
    "\n",
    "# 패딩처리를 완료하여 학습용 데이터를 완성\n",
    "enc_train = tf.keras.preprocessing.sequence.pad_sequences(src_corpus, padding='post')\n",
    "dec_train = tf.keras.preprocessing.sequence.pad_sequences(tgt_corpus, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a92ac9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 280,
       "width": 394
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 히스토그램\n",
    "plt.hist(sentence_lengths_ko, bins=20, alpha=0.7)\n",
    "plt.xlabel(\"한국어 문장 길이\")\n",
    "plt.ylabel(\"빈도\")\n",
    "plt.title(\"문장 길이 히스토그램\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "1b11f95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 280,
       "width": 394
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 히스토그램\n",
    "plt.hist(sentence_lengths_en, bins=20, alpha=0.7)\n",
    "plt.xlabel(\"영어 문장 길이\")\n",
    "plt.ylabel(\"빈도\")\n",
    "plt.title(\"문장 길이 히스토그램\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb6d0e9",
   "metadata": {},
   "source": [
    "# 2. 모델 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d6c4c0",
   "metadata": {},
   "source": [
    "## 2-1) 모델 블럭 제작"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90aeec5",
   "metadata": {},
   "source": [
    "### Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d3c8e619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, int(i) / d_model)\n",
    "\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "    return sinusoid_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3b79c4",
   "metadata": {},
   "source": [
    "### Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f17645a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "            \n",
    "        self.depth = d_model // self.num_heads\n",
    "            \n",
    "        self.W_q = tf.keras.layers.Dense(d_model)\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "            \n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "        QK = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None: scaled_qk += (mask * -1e9)  \n",
    "\n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "\n",
    "        return out, attentions\n",
    "            \n",
    "\n",
    "    def split_heads(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        split_x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
    "\n",
    "        return split_x\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        combined_x = tf.reshape(combined_x, (batch_size, -1, self.d_model))\n",
    "\n",
    "        return combined_x\n",
    "\n",
    "        \n",
    "    def call(self, Q, K, V, mask):\n",
    "        WQ = self.W_q(Q)\n",
    "        WK = self.W_k(K)\n",
    "        WV = self.W_v(V)\n",
    "        \n",
    "        WQ_splits = self.split_heads(WQ)\n",
    "        WK_splits = self.split_heads(WK)\n",
    "        WV_splits = self.split_heads(WV)\n",
    "            \n",
    "        out, attention_weights = self.scaled_dot_product_attention(\n",
    "            WQ_splits, WK_splits, WV_splits, mask)\n",
    "            \n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "                \n",
    "        return out, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cd2167",
   "metadata": {},
   "source": [
    "### FFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1a445f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.w_1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.w_2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.w_1(x)\n",
    "        out = self.w_2(out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29203e0",
   "metadata": {},
   "source": [
    "## 2-2) 모듈 조립"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3639c1d9",
   "metadata": {},
   "source": [
    "### EncoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9ff1876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "\n",
    "        \"\"\"\n",
    "        Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "        \n",
    "        \"\"\"\n",
    "        Position-Wise Feed Forward Network\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "        \n",
    "        return out, enc_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f3dd6b",
   "metadata": {},
   "source": [
    "### DecoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9745d9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "    \n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "\n",
    "        \"\"\"\n",
    "        Masked Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "\n",
    "        \"\"\"\n",
    "        Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out, dec_enc_attn = self.enc_dec_attn(out, enc_out, enc_out, causality_mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "        \n",
    "        \"\"\"\n",
    "        Position-Wise Feed Forward Network\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, dec_attn, dec_enc_attn\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5967e03d",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "bdfc6577",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                        for _ in range(n_layers)]\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "    \n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "        \n",
    "        return out, enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930fb64d",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a02d9c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                            for _ in range(n_layers)]\n",
    "                            \n",
    "                            \n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "        out = x\n",
    "    \n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = \\\n",
    "            self.dec_layers[i](out, enc_out, causality_mask, padding_mask)\n",
    "\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0193574c",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "335cb92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    src_vocab_size,\n",
    "                    tgt_vocab_size,\n",
    "                    pos_len,\n",
    "                    dropout=0.2,\n",
    "                    shared=True):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "        self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "        self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "\n",
    "        self.shared = shared\n",
    "\n",
    "        if shared: self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "\n",
    "    def embedding(self, emb, x):\n",
    "        seq_len = x.shape[1]\n",
    "        out = emb(x)\n",
    "\n",
    "        if self.shared: out *= tf.math.sqrt(self.d_model)\n",
    "\n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "        \n",
    "    def call(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask):\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "\n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "        \n",
    "        dec_out, dec_attns, dec_enc_attns = \\\n",
    "        self.decoder(dec_in, enc_out, causality_mask, dec_mask)\n",
    "        \n",
    "        logits = self.fc(dec_out)\n",
    "        \n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acf05f2",
   "metadata": {},
   "source": [
    "### mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "51785a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_causality_mask(src_len, tgt_len):\n",
    "    mask = 1 - np.cumsum(np.eye(src_len, tgt_len), 0)\n",
    "    return tf.cast(mask, tf.float32)\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_mask = generate_padding_mask(tgt)\n",
    "\n",
    "    dec_enc_causality_mask = generate_causality_mask(tgt.shape[1], src.shape[1])\n",
    "    dec_enc_mask = tf.maximum(enc_mask, dec_enc_causality_mask)\n",
    "\n",
    "    dec_causality_mask = generate_causality_mask(tgt.shape[1], tgt.shape[1])\n",
    "    dec_mask = tf.maximum(dec_mask, dec_causality_mask)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f1dc28",
   "metadata": {},
   "source": [
    "# Step 3. 훈련하기\n",
    "\n",
    "앞서 필요한 것들을 모두 정의했기 때문에 우리는 훈련만 하면 됩니다! 아래 과정을 차근차근 따라가며 모델을 훈련하고, 예문에 대한 멋진 번역을 제출하세요!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11152ba6",
   "metadata": {},
   "source": [
    "## 3-1) Transformer 선언\n",
    "\n",
    "2 Layer를 가지는 Transformer를 선언하세요.\n",
    "(하이퍼파라미터는 자유롭게 조절합니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4f1b0403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Layer Transformer 선언\n",
    "transformer = Transformer(\n",
    "    n_layers=2,              # 레이어 개수 (2개)\n",
    "    d_model=512,             # 모델 차원\n",
    "    n_heads=8,               # 헤드 개수\n",
    "    d_ff=2048,               # 피드 포워드 네트워크 차원\n",
    "    src_vocab_size=SRC_VOCAB_SIZE,  # 소스 어휘 크기\n",
    "    tgt_vocab_size=TGT_VOCAB_SIZE,  # 타겟 어휘 크기\n",
    "    pos_len=200,             # 포지셔널 인코딩 최대 길이\n",
    "    dropout=0.2,             # 드롭아웃 확률\n",
    "    shared=True              # 임베딩 공유 여부\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3365ec59",
   "metadata": {},
   "source": [
    "## 3-2) learning_rate, optimizer, Loss정의\n",
    "\n",
    "논문에서 사용한 것과 동일한 Learning Rate Scheduler를 선언하고, 이를 포함하는 Adam Optimizer를 선언하세요.\n",
    " (Optimizer의 파라미터 역시 논문과 동일하게 설정합니다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b53e167",
   "metadata": {},
   "source": [
    "### learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c18414cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "learning_rate = LearningRateScheduler(512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d717723",
   "metadata": {},
   "source": [
    "### optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cb2dff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                     beta_1=0.9,\n",
    "                                     beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71182ec",
   "metadata": {},
   "source": [
    "### Loss\n",
    "\n",
    "Sequence-to-sequence 모델에서 사용했던 Loss와 유사하되, Masking 되지 않은 입력의 개수로 Scaling하는 과정을 추가합니다. (트랜스포머가 모든 입력에 대한 Loss를 한 번에 구하기 때문입니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "fedfa24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    # Masking 되지 않은 입력의 개수로 Scaling하는 과정\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b202393b",
   "metadata": {},
   "source": [
    "## 3-3) Train_step\n",
    "\n",
    "\n",
    "train_step 함수를 정의하세요.\n",
    "입력 데이터에 알맞은 Mask를 생성하고, 이를 모델에 전달하여 연산에서 사용할 수 있게 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e1e051eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    gold = tgt[:, 1:]  # 정답 데이터\n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt)  # 마스크 생성\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        model(src, tgt, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions[:, :-1])  # 손실 계산\n",
    "\n",
    "    # 최종적으로 optimizer.apply_gradients()가 사용됩니다.\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)  # 기울기 계산\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))  # 기울기 적용\n",
    "\n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fc2deb",
   "metadata": {},
   "source": [
    "### 번역생성 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "189ca37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention 시각화 함수\n",
    "\n",
    "def visualize_attention(src, tgt, enc_attns, dec_attns, dec_enc_attns):\n",
    "    def draw(data, ax, x=\"auto\", y=\"auto\"):\n",
    "        import seaborn\n",
    "        seaborn.heatmap(data, \n",
    "                        square=True,\n",
    "                        vmin=0.0, vmax=1.0, \n",
    "                        cbar=False, ax=ax,\n",
    "                        xticklabels=x,\n",
    "                        yticklabels=y)\n",
    "        \n",
    "    for layer in range(0, 2, 1):\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        print(\"Encoder Layer\", layer + 1)\n",
    "        for h in range(4):\n",
    "            draw(enc_attns[layer][0, h, :len(src), :len(src)], axs[h], src, src)\n",
    "        plt.show()\n",
    "        \n",
    "    for layer in range(0, 2, 1):\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        print(\"Decoder Self Layer\", layer+1)\n",
    "        for h in range(4):\n",
    "            draw(dec_attns[layer][0, h, :len(tgt), :len(tgt)], axs[h], tgt, tgt)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Decoder Src Layer\", layer+1)\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        for h in range(4):\n",
    "            draw(dec_enc_attns[layer][0, h, :len(tgt), :len(src)], axs[h], src, tgt)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5fd3d317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역 생성 함수\n",
    "\n",
    "def evaluate(sentence, model, src_tokenizer, tgt_tokenizer):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    pieces = src_tokenizer.encode_as_pieces(sentence)\n",
    "    tokens = src_tokenizer.encode_as_ids(sentence)\n",
    "\n",
    "    _input = tf.keras.preprocessing.sequence.pad_sequences([tokens],\n",
    "                                                           maxlen=enc_train.shape[-1],\n",
    "                                                           padding='post')\n",
    "    \n",
    "    ids = []\n",
    "    output = tf.expand_dims([tgt_tokenizer.bos_id()], 0)\n",
    "    for i in range(dec_train.shape[-1]):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
    "        generate_masks(_input, output)\n",
    "\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns =\\\n",
    "        model(_input, \n",
    "              output,\n",
    "              enc_padding_mask,\n",
    "              combined_mask,\n",
    "              dec_padding_mask)\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "\n",
    "        if tgt_tokenizer.eos_id() == predicted_id:\n",
    "            result = tgt_tokenizer.decode_ids(ids)\n",
    "            return pieces, result, enc_attns, dec_attns, dec_enc_attns\n",
    "\n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "\n",
    "    result = tgt_tokenizer.decode_ids(ids)\n",
    "\n",
    "    return pieces, result, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b4e834ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역 생성 및 Attention 시각화 결합\n",
    "\n",
    "def translate(sentence, model, src_tokenizer, tgt_tokenizer, plot_attention=False):\n",
    "    pieces, result, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "    evaluate(sentence, model, src_tokenizer, tgt_tokenizer)\n",
    "    \n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    if plot_attention:\n",
    "        visualize_attention(pieces, result.split(), enc_attns, dec_attns, dec_enc_attns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff827545",
   "metadata": {},
   "source": [
    "## 3-4) training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "282a2a7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39/3013602775.py:22: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  t = tqdm_notebook(idx_list)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29758dc5019746c0bc71cfcc1ea60ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/714 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama is a great time .\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: the time was a day of the country such .\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: the time is a great .\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: the attack was killed in the attack in the attack .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970dc2546fce49ed8dcab55ebc2a9f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/714 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama is a lot of the president , but it is a lot of the president , he says .\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: the city s mainest buses .\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: it was not immediately to do it s not very good .\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: the blast was reportedly killed in the blast , the southwestern city of the blasts reported .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60d8e523a1774964958b23cb9eacbc41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/714 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama is a new president .\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: the people seen in the city .\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: it is not going to be going .\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: the death toll was reported .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9200e16934674587baa99c5eb8972589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/714 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama is the appointment .\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: the city of water city city .\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: there is no doubt .\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: the death toll was reported .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3257abb1b1ac46b4978b73e6e2517f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/714 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: the obama is a key partner of president .\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: they are the highest of the people .\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: coffees cannot afford coffee .\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: the death toll from seven death tolls sunday morning .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4780d29dcbce4106957d4553deef4216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/714 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: if obama is changing .\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: people have been in the city .\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: it is not easy .\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: the death toll from saturday s dead .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "257d063815304180acc57000b548f81c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/714 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama is the president .\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: the people city of sir edmund has been forced to .\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: coffee you can never use .\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: the death toll from monday between .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24edfe2f8e5a42b7800f0e2d9b83a10b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/714 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama is the nominee of the country .\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: they d put the city streets .\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: not everyone cannot give you anything to do .\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: nine people have died sunday after seven days .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da7fb4592c9947008dec107d2000a6ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/714 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama is increasings into the country .\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: people they were expected in countryside .\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: if coffee did not show that you need to show that coffee .\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: on wednesday , the death toll was .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34ef2f7244b1491b9db6824751ab90c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/714 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama is picking up a vehicle .\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: they put the streets in the city .\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: if you have to show you average price .\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: the seven died sunday of the dead . there have been seven dead . there . there have been dead . there . there are dead . there are dead . there , the dead . there are still historic .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee2797b22b704a39a9031ba1c4536924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/714 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39/3013602775.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch %2d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss %.4f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "\n",
    "from tqdm import tqdm_notebook \n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "\n",
    "examples = [\n",
    "            \"오바마는 대통령이다.\",\n",
    "            \"시민들은 도시 속에 산다.\",\n",
    "            \"커피는 필요 없다.\",\n",
    "            \"일곱 명의 사망자가 발생했다.\"\n",
    "]\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm_notebook(idx_list)\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        train_step(enc_train[idx:idx+BATCH_SIZE],\n",
    "                    dec_train[idx:idx+BATCH_SIZE],\n",
    "                    transformer,\n",
    "                    optimizer)\n",
    "\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
    "        \n",
    "\n",
    "    for example in examples:\n",
    "        translate(example, transformer, ko_tokenizer, en_tokenizer, plot_attention=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e7c38a",
   "metadata": {},
   "source": [
    "# 테스트기록"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0891e7f0",
   "metadata": {},
   "source": [
    "### (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed243b7",
   "metadata": {},
   "source": [
    "- Input: 오바마는 대통령이다.\n",
    "- Predicted translation: obama is the president .\n",
    "- Input: 시민들은 도시 속에 산다.\n",
    "- Predicted translation: the city s most important\n",
    "- Input: 커피는 필요 없다.\n",
    "- Predicted translation: the people are being .\n",
    "- Input: 일곱 명의 사망자가 발생했다.\n",
    "- Predicted translation: the u . s . house was in ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1cb78b",
   "metadata": {},
   "source": [
    "첫번째 문장은 잘 해석했으나 나머지 문장의 해석이 부족함\n",
    "- 테스트 문장의 개수 20000 -> 50000 로 증강 후 재학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c096a3dc",
   "metadata": {},
   "source": [
    "### (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc0864c",
   "metadata": {},
   "source": [
    "Input: 오바마는 대통령이다.\n",
    "\n",
    "Predicted translation: obama is the nominee of the country .\n",
    "\n",
    "Input: 시민들은 도시 속에 산다.\n",
    "\n",
    "Predicted translation: they d put the city streets .\n",
    "\n",
    "Input: 커피는 필요 없다.\n",
    "\n",
    "Predicted translation: not everyone cannot give you anything to do .\n",
    "\n",
    "Input: 일곱 명의 사망자가 발생했다.\n",
    "\n",
    "Predicted translation: nine people have died sunday after seven days ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e643af38",
   "metadata": {},
   "source": [
    "- 문장 증강후 표현력이 늘었음\n",
    "- 7epoch 이후로 loss는 줄었지만, 문장의 완성도는 줄어듬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968db373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
