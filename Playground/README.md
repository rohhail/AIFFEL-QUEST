ğŸ”‘ **PRT(Peer Review Template)**

- [x]  **1. ì£¼ì–´ì§„ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ì™„ì„±ëœ ì½”ë“œê°€ ì œì¶œë˜ì—ˆë‚˜ìš”? (ì™„ì„±ë„)**
    - [x] ë¬¸ì œì—ì„œ ìš”êµ¬í•˜ëŠ” ìµœì¢… ê²°ê³¼ë¬¼ì´ ì²¨ë¶€ë˜ì—ˆëŠ”ì§€ í™•ì¸
    - [x] ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ì™„ì„±ëœ ì½”ë“œë€ í”„ë¡œì íŠ¸ ë£¨ë¸Œë¦­ 3ê°œ ì¤‘ 2ê°œ,
    í€˜ìŠ¤íŠ¸ ë¬¸ì œ ìš”êµ¬ì¡°ê±´ ë“±ì„ ì§€ì¹­
        - [x] í•´ë‹¹ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ë¶€ë¶„ì˜ ì½”ë“œ ë° ê²°ê³¼ë¬¼ì„ ìº¡ì³í•˜ì—¬ ì‚¬ì§„ìœ¼ë¡œ ì²¨ë¶€
```py
class CustomModel(keras.Model):
    def train_step(self, data):
        inputs, targets = data
        with tf.GradientTape() as tape:
            predictions = self(inputs, training=True)
            loss = self.compiled_loss(targets, predictions)
        gradients = tape.gradient(loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))
        self.compiled_metrics.update_state(targets, predictions)
        return {m.name: m.result() for m in self.metrics}

inputs = keras.Input(shape=(28 * 28,))
features = layers.Dense(512, activation="relu")(inputs)
features = layers.Dropout(0.5)(features)
outputs = layers.Dense(10, activation="softmax")(features)
model = CustomModel(inputs, outputs)

model.compile(optimizer=keras.optimizers.RMSprop(),
              loss=keras.losses.SparseCategoricalCrossentropy(),
              metrics=[keras.metrics.SparseCategoricalAccuracy()])
model.fit(train_images, train_labels, epochs=3)
```

- ~~[x]  **2. í”„ë¡œì íŠ¸ì—ì„œ í•µì‹¬ì ì¸ ë¶€ë¶„ì— ëŒ€í•œ ì„¤ëª…ì´ ì£¼ì„(ë‹¥ìŠ¤íŠ¸ë§) ë° ë§ˆí¬ë‹¤ìš´ í˜•íƒœë¡œ ì˜ ê¸°ë¡ë˜ì–´ìˆë‚˜ìš”? (ì„¤ëª…)**~~
    - [x] ~~ëª¨ë¸ ì„ ì • ì´ìœ : ëª¨ë¸ì´ ì •í•´ì ¸ìˆì—ˆë‹¤.~~
    - [x]  ~~Metrics ì„ ì • ì´ìœ : ë©”íŠ¸ë¦­ì´ ì •í•´ì ¸ ìˆì—ˆë‹¤.~~
    - [x]  ~~Loss ì„ ì • ì´ìœ : ì´í•˜ ë™ì¼~~

- [x]  ~~**3. ì²´í¬ë¦¬ìŠ¤íŠ¸ì— í•´ë‹¹í•˜ëŠ” í•­ëª©ë“¤ì„ ëª¨ë‘ ìˆ˜í–‰í•˜ì˜€ë‚˜ìš”? (ë¬¸ì œ í•´ê²°)**~~
    - [ ]  ë°ì´í„°ë¥¼ ë¶„í• í•˜ì—¬ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í–ˆë‚˜ìš”? (train, validation, test ë°ì´í„°ë¡œ êµ¬ë¶„)
    - [ ]  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ë³€ê²½í•´ê°€ë©° ì—¬ëŸ¬ ì‹œë„ë¥¼ í–ˆë‚˜ìš”? (learning rate, dropout rate, unit, batch size, epoch ë“±)
    - [ ]  ê° ì‹¤í—˜ì„ ì‹œê°í™”í•˜ì—¬ ë¹„êµí•˜ì˜€ë‚˜ìš”?
    - [ ]  ëª¨ë“  ì‹¤í—˜ ê²°ê³¼ê°€ ê¸°ë¡ë˜ì—ˆë‚˜ìš”?

- [x]  **4. í”„ë¡œì íŠ¸ì— ëŒ€í•œ íšŒê³ ê°€ ìƒì„¸íˆ ê¸°ë¡ ë˜ì–´ ìˆë‚˜ìš”? (íšŒê³ , ì •ë¦¬)**
    - [x]  ë°°ìš´ ì 
    - [x]  ì•„ì‰¬ìš´ ì 
    - [x]  ëŠë‚€ ì 
    - [x]  ì–´ë ¤ì› ë˜ ì 
    

## íšŒê³ 
**1. ë°°ìš´ ì **
 - ë‹¨ìˆœ Sequential ëª¨ë¸ë¡œ ë³´ë‹¤ê°€ í•¨ìˆ˜í˜• API, Model ì„œë¸Œí´ë˜ì‹± ë“±ìœ¼ë¡œ ëª¨ë¸ì„ ë§Œë“œëŠ” ì˜ˆì‹œë¥¼ ë³´ë©° ëª¨ë¸ì˜ í•™ìŠµ í”„ë¡œì„¸ìŠ¤ì— ëŒ€í•´ ë” ì˜ ì´í•´í•  ìˆ˜ ìˆì—ˆìŒ.
 
**2. ì•„ì‰¬ìš´ ì **
 - ì•„ì§ ì‚¬ì§ì ‘ ëª¨ë¸ë§ í•´ë³¸ë‹¤ë©´ ì—¬ë ¤ìš¸ ê²ƒ ê°™ë‹¤ëŠ” ìƒê°ì´ ë“¤ì—ˆìŒ.

**3. ëŠë‚€ ì **

**4. ì–´ë ¤ì› ë˜ ì **
 - ë‹¨ìˆœ ëª¨ë¸ë“¤ë§Œ ë³´ë‹¤ê°€ ì‚¬ìš©ì ì •ì˜ ëª¨ë¸ì„ ë³´ë‹ˆ ì½”ë“œì˜ ë³µì¡ë„ê°€ ë†’ì•„ ì´í•´í•˜ê¸° ì—¬ë ¤ì› ìŒ
 
